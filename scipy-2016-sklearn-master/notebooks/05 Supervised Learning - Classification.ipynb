{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: Mueller, Kyle Kastner, Sebastian Raschka'"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a \"'\"Andreas Mueller, Kyle Kastner, Sebastian Raschka\"'\" -v -p numpy,scipy,matplotlib,pillow,scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy 2016 Scikit-learn Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Part 1 -- Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the workings of machine learning algorithms, it is often helpful to study two-dimensional or one-dimensional data, that is data with only one or two features. While in practice, datasets usually have many more features, it is hard to plot high-dimensional data in on two-dimensional screens.\n",
    "\n",
    "We will illustrate some very simple examples before we move on to more \"real world\" data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, we will look at a two class classification problem in two dimensions. We use the synthetic data generated by the ``make_blobs`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X ~ n_samples x n_features:', (100, 2))\n",
      "('y ~ n_samples:', (100,))\n",
      "('\\nFirst 5 samples:\\n', array([[ 4.21850347,  2.23419161],\n",
      "       [ 0.90779887,  0.45984362],\n",
      "       [-0.27652528,  5.08127768],\n",
      "       [ 0.08848433,  2.32299086],\n",
      "       [ 3.24329731,  1.21460627]]))\n",
      "('\\nFirst 5 labels:', array([1, 1, 0, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(centers=2, random_state=0)\n",
    "\n",
    "print('X ~ n_samples x n_features:', X.shape)\n",
    "print('y ~ n_samples:', y.shape)\n",
    "\n",
    "print('\\nFirst 5 samples:\\n', X[:5, :])\n",
    "print('\\nFirst 5 labels:', y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is two-dimensional, we can plot each sample as a point in a two-dimensional coordinate system, with the first feature being the x-axis and the second feature being the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEPCAYAAABP1MOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCTj/j9dLnyuuA30lAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x56faeb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], \n",
    "            c='blue', s=40, label='0')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], \n",
    "            c='red', s=40, label='1', marker='s')\n",
    "\n",
    "plt.xlabel('first feature')\n",
    "plt.ylabel('second feature')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a supervised task, and since we are interested in its performance on unseen data, we split our data into two parts:\n",
    "\n",
    "1. a training set that the learning algorithm uses to fit the model\n",
    "2. a test set to evaluate the generalization performance of the model\n",
    "\n",
    "The ``train_test_split`` function from the ``model_selection`` module does that for us -- we will use it to split a dataset into 75% training data and 25% test data.\n",
    "\n",
    "<img src=\"figures/train_test_split_matrix.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-edbd0b5c31cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test = train_test_split(X, y,\n\u001b[0;32m      4\u001b[0m                                                     \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named model_selection"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=1234,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scikit-learn estimator API\n",
    "<img src=\"figures/supervised_workflow.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every algorithm is exposed in scikit-learn via an ''Estimator'' object. (All models in scikit-learn have a very consistent interface). For instance, we first import the logistic regression class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To built the model from our data, that is to learn how to classify new points, we call the ``fit`` function with the training data, and the corresponding training labels (the desired output for the training data point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Some estimator methods such as `fit` return `self` by default. Thus, after executing the code snippet above, you will see the default parameters of this particular instance of `LogisticRegression`. Another way of retrieving the estimator's ininitialization parameters is to execute `classifier.get_params()`, which returns a parameter dictionary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then apply the model to unseen data and use the model to predict the estimated outcome using the ``predict`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare these against the true labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(prediction)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate our classifier quantitatively by measuring what fraction of predictions is correct. This is called **accuracy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a convenience function , ``score``, that all scikit-learn classifiers have to compute this directly from the test data:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often helpful to compare the generalization performance (on the test set) to the performance on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression is a so-called linear model,\n",
    "that means it will create a decision that is linear in the input space. In 2d, this simply means it finds a line to separate the blue from the red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from figures import plot_2d_separator\n",
    "\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], \n",
    "            c='blue', s=40, label='0')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], \n",
    "            c='red', s=40, label='1', marker='s')\n",
    "\n",
    "plt.xlabel(\"first feature\")\n",
    "plt.ylabel(\"second feature\")\n",
    "plot_2d_separator(classifier, X)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimated parameters**: All the estimated model parameters are attributes of the estimator object ending by an underscore. Here, these are the coefficients and the offset of the line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classifier.coef_)\n",
    "print(classifier.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another classifier: K Nearest Neighbors\n",
    "------------------------------------------------\n",
    "Another popular and easy to understand classifier is K nearest neighbors (kNN).  It has one of the simplest learning strategies: given a new, unknown observation, look up in your reference database which ones have the closest features and assign the predominant class.\n",
    "\n",
    "The interface is exactly the same as for ``LogisticRegression above``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we set a parameter of the KNeighborsClassifier to tell it we only want to look at one nearest neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model with out training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], \n",
    "            c='blue', s=40, label='0')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], \n",
    "            c='red', s=40, label='1', marker='s')\n",
    "\n",
    "plt.xlabel(\"first feature\")\n",
    "plt.ylabel(\"second feature\")\n",
    "plot_2d_separator(knn, X)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "=========\n",
    "Apply the KNeighborsClassifier to the ``iris`` dataset. Play with different values of the ``n_neighbors`` and observe how training and test score change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/05A_knn_with_diff_k.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
